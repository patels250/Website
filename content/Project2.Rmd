---
title: "Project 2 (Modeling, Testing, and Predicting)"
author: "Sagar Patel"
date: '2020-05-01'
output:
  html_document:
    toc: yes
    toc_float:
      collapsed: no
      smooth_scroll: yes
  pdf_document:
    toc: yes
---

```{r setup, include=FALSE}
library(knitr)
hook_output = knit_hooks$get('output')
knit_hooks$set(output = function(x, options) {
  # this hook is used only when the linewidth option is not NULL
  if (!is.null(n <- options$linewidth)) {
    x = knitr:::split_lines(x)
    # any lines wider than n should be wrapped
    if (any(nchar(x) > n)) x = strwrap(x, width = n)
    x = paste(x, collapse = '\n')
  }
  hook_output(x, options)
})

knitr::opts_chunk$set(echo = TRUE, eval = TRUE,fig.align="center",warning=FALSE,message=FALSE,fig.width=8, fig.height=5, linewidth=60)
options(tibble.width = 100,width = 100)
library(tidyverse)
library(readxl)
library(lmtest)
library('interactions')
library(sandwich)
library(plotROC)
library(glmnet)
```

# Introduction:

I am using the same datasets from Project 1. These datasets contain NFL player statistics from the 2019 regular season, as retrieved from Pro-Football-Reference. One dataset contains all rushing stats for applicable players and the other contains all receiving stats for applicable players. For the purposes of this project, these two datasets will be full joined together. We will also only be including skill position players (running back (RB), wide receiver (WR), and tight end (TE)) for this project. Variables that can be retrieved from other variables such as "yards per game" and trivial variables such as "longest play" have been excluded. 

The final dataset has 469 observations (players) for 17 variables. These variables include personal information (such as player name, team, age, and position) as well as numeric statistics (such as games played, receiving yards, rushing yards, receiving touchdowns, rushing touchdowns, etc.). Using the dplyr mutate function, I have created two variables: "Total Yards" which is the sum of receiving and rushing yards and "Total TDs" which is the sum of receiving and rushing TDs. I have also manually created a "Pro_Bowl" binary variable that shows 1 if the player made it to the Pro Bowl and 0 if the player did not make it to the Pro Bowl (the Pro Bowl is an "all-star game" of sorts for the NFL, i.e. only the best players make it to the Pro Bowl). 

```{r}
rushing <- read_excel('Rushing2.xlsx', 
    col_types = c('numeric', 'text', 'text', 
        'numeric', 'text', 'numeric', 'numeric', 
        'numeric', 'numeric', 'numeric', 
        'numeric', 'numeric', 'numeric', 
        'numeric', 'numeric', 'numeric'))

receiving <- read_excel('Receiving2.xlsx', 
    col_types = c('numeric', 'text', 'text', 
        'numeric', 'text', 'numeric', 'numeric', 
        'numeric', 'numeric', 'numeric', 
        'numeric', 'numeric', 'numeric', 
        'numeric', 'numeric', 'numeric', 
        'numeric', 'numeric', 'numeric', 'numeric'))

rushing$Pos <- toupper(rushing$Pos)
rushing <- rushing %>% select(-'Rk', -'Y/A', -'Y/G', -'Lng', -'1D') %>% 
  rename(Rush_Yds = 'Yds', Rush_TD = 'TD')

receiving$Pos <- toupper(receiving$Pos)
receiving <- receiving %>% 
  select(-'Rk', -'Ctch%', -'Y/R', -'Y/Tgt', -'R/G', -'Y/G', -'Lng', -'1D') %>% 
  rename(Rec_Yds = 'Yds', Rec_TD = 'TD')

full_dat <- rushing %>% full_join(receiving)
full_dat[is.na(full_dat)] <- 0
full_dat <- full_dat %>% filter(Pos == 'RB' | Pos == 'WR' | Pos == 'TE') %>% 
  mutate(Tot_Yds = Rec_Yds + Rush_Yds, Tot_TD = Rec_TD + Rush_TD) %>% arrange(Player)
```

# MANOVA Test:

First, we will perform a MANOVA test to see whether the number of total yards, total touchdowns, and fumbles show a mean difference across the three different positions (RB, WR, TE). With a p-value of 1.029e-09, this test was significant. 

```{r}
man1 <- manova(cbind(Tot_Yds, Tot_TD, Fmb) ~ Pos, data = full_dat)
summary(man1)
```

As a result, we will perform univariate ANOVA tests to see which variables differed specifically. All three univariate ANOVA tests were significant, meaning that rush yards, receiving yards, and fumbles all differed across position groups. 

```{r}
summary.aov(man1)
```

Finally, we will perform post-hoc t-tests to see which position groups specifically differed in each variable. Because we performed 13 total tests (1 MANOVA, 3 ANOVAs, and 9 t-tests), we will have to make a Bonferroni correction to our significance level. The Bonferroni corrected significance level is 0.00385. Using this new significance level, we can see that RBs and TEs as well as WRs and TEs differed significantly in total yards. RBs and TEs as well as RBs and WRs differed significantly in both total TDs and fumbles.

```{r}
full_dat %>% group_by(Pos) %>% summarize(mean(Rush_Yds), mean(Rec_Yds), mean(Fmb))
pairwise.t.test(full_dat$Tot_Yds, full_dat$Pos, p.adj = 'none')
pairwise.t.test(full_dat$Tot_TD, full_dat$Pos, p.adj = 'none')
pairwise.t.test(full_dat$Fmb, full_dat$Pos, p.adj = 'none')
```

In terms of assumptions, it is not likely that this dataset meets any of the assumptions of a MANOVA test. Observations are not independent because if, for example, one running back is receiving lots of carries and yards, then other running backs on the same team are not. The data is also not normal. This is because EVERY player (of the given positions of course) who touched the ball even once during the season is included in this dataset. This means the data for each variable is heavily right/positively skewed.

# Randomization Test:

We will perform a randomization test to see if the mean Total Yards differs between WRs and RBs. The hypotheses are as follows: 

H~O~: Mean total yards are the same for wide receivers and running backs.

H~A~: Mean total yards are different for wide receivers and running backs.

We can see that the mean total yards for RBs is 507.9104 and the mean total yards for WRs is 383.9954. This is a mean difference of 123.9151. 

```{r}
WRRB <- full_dat %>% filter(Pos != 'TE') %>% select(Pos, Tot_Yds)
WRRB %>% group_by(Pos) %>% summarize(means = mean(Tot_Yds))
WRRB %>% group_by(Pos) %>% summarize(means = mean(Tot_Yds)) %>% 
  summarize(`mean_diff:` = diff(means))
```

Using 5,000 random permutations and our original mean difference of 123.9151, we get a p-value of 0.011. This is lower than our significance level of 0.05 meaning we reject the null hypothesis. The randomization test shows that mean total yards differs between wide receivers and running backs.

```{r}
set.seed(1234)
rand_dist <- vector()
for(i in 1:5000){
new <- data.frame(Tot_Yds = sample(WRRB$Tot_Yds), Pos = WRRB$Pos)
rand_dist[i] <- mean(new[new$Pos == 'RB',]$Tot_Yds) - mean(new[new$Pos == 'WR',]$Tot_Yds)}

hist(rand_dist, main = '', ylab = ''); abline(v = -123.9151, col = 'red')
mean(rand_dist > 123.9151 | rand_dist < -123.9151)
```

# Linear Regression

We will perform a linear regression in which we attempt to predict the number of total touchdowns a player will score based on the number of rushing attempts and receiving targets he has. The coefficient estimates can be interpreted as follows: for every rushing attempt a player has above the mean, his total TDs will increase by 2.836e-02. For every receiving target a player has above the mean, his total TDs will increase by 4.841e-02. The adjusted R-squared value of 0.6746 means 67.46% of the variation in total TDs is explained by rushing attempts and receiving targets. A graph of the interaction can be found below. As shown in both the graph and the regression summary, the interaction is not significant.

```{r}
centered <- full_dat %>% mutate(Att_c = full_dat$Att - mean(full_dat$Att),
                                Tgt_c = full_dat$Tgt - mean(full_dat$Tgt))
linfit <- lm(Tot_TD ~ Att_c * Tgt_c, data = centered)
summary(linfit)
interact_plot(linfit, pred = Att_c, modx = Tgt_c)
```

As we can see from the plot below, the data is not linear. The Breusch-Pagan test for homoskedasticity gives us a p-value of <2.2e-16. This means we reject the null hypothesis, meaning the data is not homoskedastic. The Shapiro-Wilk normality test also gives us a p-value of <2.2e-16. This means we reject the null hypothesis, meaning the data is not normal. The data has failed all three assumptions.

```{r}
centered %>% ggplot(aes(Att_c, Tgt_c)) + geom_point() + geom_smooth(method = 'lm', se = F)
resids <- linfit$residuals
bptest(linfit)
shapiro.test(resids)
```  

Next we will recompute the regression results with robust standard errors. The standard error for mean-centered rushing attempts doubled and the standard error for mean-centered receiving targets almost doubled. The end result is the same: both rushing attempts and receiving targets are significant predictors of total touchdowns, but their interaction is not.

```{r}
coeftest(linfit, vcov = vcovHC(linfit))
```

Because our assumptions were violated, it is more effective to use bootstrapped standard errors. We will perform bootstrapping by resampling rows and not residuals. The standard errors from bootstrapping are more similar to the robust standard errors than to the original standard errors.

```{r}
samp_distn <- replicate(5000,{
boot_dat <- sample_frac(centered, replace=T)
bootfit <- lm(Tot_TD ~ Att_c * Tgt_c, data = boot_dat)
coef(bootfit)
})
samp_distn %>% t %>% as.data.frame %>% summarize_all(sd)
```

# Logistic Regression

We will perform a logistic regression in which we attempt to predict whether a player will make the Pro Bowl based on the number of games they played and their game statistics. The significant predictors were games played, rushing attempts, rushing yards, and receiving touchdowns. When we exponentiate the significant coefficients, we can see that for each game a player plays, his odds of making the Pro Bowl are multiplied by 0.458. For every rushing attempt a player has, his odds of making the Pro Bowl are multiplied by 0.872. For every rushing yard a player has, his odds of making the Pro Bowl are multiplied by 1.037. For every receiving touchdown a player has, his odds of making the Pro Bowl are multiplied by 1.957.

```{r}
class_diag <- function(probs, truth){
tab <- table(factor(probs > .5, levels = c('FALSE', 'TRUE')), truth)
acc = sum(diag(tab))/sum(tab)
sens = tab[2,2]/colSums(tab)[2]
spec = tab[1,1]/colSums(tab)[1]
ppv = tab[2,2]/rowSums(tab)[2]
if(is.numeric(truth) == FALSE & is.logical(truth) == FALSE) truth <- as.numeric(truth) - 1
ord <- order(probs, decreasing = TRUE)
probs <- probs[ord]; truth <- truth[ord]
TPR = cumsum(truth)/max(1, sum(truth)) 
FPR = cumsum(!truth)/max(1, sum(!truth))
dup <- c(probs[-1] >= probs[-length(probs)], FALSE)
TPR <- c(0, TPR[!dup], 1); FPR <- c(0, FPR[!dup], 1)
n <- length(TPR)
auc <- sum(((TPR[-1] + TPR[-n])/2) * (FPR[-1] - FPR[-n]))
data.frame(acc, sens, spec, ppv, auc)
}
logfit <- glm(Pro_Bowl ~ Pos + G + GS + Att + Rush_Yds + Rush_TD + Tgt + Rec + Rec_Yds + 
                Rec_TD + Fmb, data = full_dat, family = 'binomial')
coeftest(logfit)
exp(coef(logfit))
```

We will analyze how well our model performs. The confusion matrix shows that out of the 26 actual Pro Bowlers, the model only correctly predicted 17 of them. The accuracy, sensitivity, specificity, precision, and AUC can be seen below. The AUC of 0.9868901 means our model performs very well. 

```{r}
full_dat$prob <- predict(logfit, type = 'response')
table(predict = as.numeric(full_dat$prob > .5), truth = full_dat$Pro_Bowl) %>% addmargins
class_diag(full_dat$prob, full_dat$Pro_Bowl)
```

A density plot of the log-odds can be found below. The ROC curve shows that the model is near perfect.

```{r}
full_dat$logit <- predict(logfit, type = 'link')
full_dat <- full_dat %>% mutate(y = ifelse(Pro_Bowl == 1, 'Yes', 'No'))
full_dat %>% ggplot() + geom_density(aes(logit, color = y, fill = y), alpha = .4) +
  theme(legend.position = c(.85, .85)) + geom_vline(xintercept = 0) + 
  xlab('logit (log-odds)') +
  geom_rug(aes(logit, color = y)) +
  geom_text(x = -11, y = .03, label = 'TN = 437') +
  geom_text(x = -2.25, y=.008, label = 'FN = 9') +
  geom_text(x = 1.2, y = .006, label = 'FP = 6') +
  geom_text(x = 2, y = .04, label = 'TP = 17')
full_dat %>% ggplot() + geom_roc(aes(d = Pro_Bowl, m = prob), n.cuts = 0)
```

We will perform a repeated random sub-sampling cross-validation of our logistic regression model to analyze out-of-sample performance. As seen below, our classification diagnostics are nearly identical to the ones above from our original logistic regression model. Our model performs very well out-of-sample with an AUC of 0.9870627.

```{r}
set.seed(1234)
fraction <- 0.5
train_n <- floor(fraction * nrow(full_dat))
iter <- 500
diags <- NULL
for(i in 1:iter){
train_index <- sample(1:nrow(full_dat), size=train_n)
train <- full_dat[train_index,]
test <- full_dat[-train_index,]
truth <- test$Pro_Bowl
fit <- glm(Pro_Bowl ~ Pos + G + GS + Att + Rush_Yds + Rush_TD + Tgt + Rec + Rec_Yds + 
             Rec_TD + Fmb, data = full_dat, family = 'binomial')
probs <- predict(fit, newdata = test, type = 'response')
diags <- rbind(diags, class_diag(probs, truth))
}
summarize_all(diags, mean)
```

We will perform a LASSO regression to determine which variables are the best predictors. These variables were rushing touchdowns, receptions, receiving yards, and receiving touchdowns.

```{r}
y <- as.matrix(full_dat$Pro_Bowl)
x <- model.matrix(Pro_Bowl ~ Pos + G + GS + Att + Rush_Yds + Rush_TD + Tgt + Rec + 
                    Rec_Yds + Rec_TD + Fmb, data=full_dat)[,-1]
x <- scale(x)
cv <- cv.glmnet(x, y, family = 'binomial')
lasso <- glmnet(x, y, family = 'binomial', lambda = cv$lambda.1se)
coef(lasso)
```

We will now perform a repeated random sub-sampling cross-validation of our LASSO model using only the aforementioned variables. Our classification diagnostics show that the sensitivity and precision have dropped from the original cross-validation above. Our model still performs very well out-of-sample with an AUC of 0.9744991.

```{r}
set.seed(1234)
fraction <- 0.5
train_n <- floor(fraction * nrow(full_dat)) 
iter <- 500 
diags <- NULL
for(i in 1:iter){
train_index <- sample(1:nrow(full_dat), size=train_n)
train <- full_dat[train_index,]
test <- full_dat[-train_index,]
truth <- test$Pro_Bowl
fit <- glm(Pro_Bowl ~ Rush_TD + Rec + Rec_Yds + Rec_TD, data = full_dat,
           family = 'binomial')
probs <- predict(fit, newdata = test, type = 'response')
diags <- rbind(diags, class_diag(probs,truth))
}
summarize_all(diags, mean)
```

Just for fun, let's create a hypothetical scenario where I am an NFL player. We will give my hypothetical player stats for the season and see what the probability of me making the Pro Bowl is using our original logistic regression model. My hypothetical player is a wide receiver who was healthy for and started every game of the season. Like most wide receivers, my rushing stats are near nonexistant. Let's say I had 5 attempts for 24 yards and 0 touchdowns. In terms of targets, we will say I had 134 targets and caught 111 of them for 1254 yards and 9 touchdowns. Let's say I had 2 fumbles on the season. According to our logistic regression model, my hypothetical player has a 83.06% chance of making the Pro Bowl with those stats. Now, it's important to know how the Pro Bowl works. Players are voted into the Pro Bowl by journalists and partly by fans. There is no algorithm that decides who makes the Pro Bowl. There is likely some bias in the journalists' and fans' votes towards players on the team they support or players who had good "stories" this season, such as a player that missed the entire last season due to a gruesome injury and performed very well this year. Because of this, even a "perfect" logistic regression model could fail to predict some players' entry to the Pro Bowl. 

```{r}
Sagar <- data.frame(Pos = 'WR', G = 16, GS = 16, Att = 5, Rush_Yds = 24, Rush_TD = 0, Tgt = 134, Rec = 111, Rec_Yds = 1254, Rec_TD = 9, Fmb = 2)
predict(logfit, newdata = Sagar, type = 'response')
```

